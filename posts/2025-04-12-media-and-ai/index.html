<!doctype html><html lang=en><head><meta charset=utf-8><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content="light dark" name=color-scheme><meta content="Essays and notes about all sorts of things" name=description><title>Media Manipulation With AI</title><link href=/favicon-16.png rel=icon sizes=16x16 type=image/png><link href=/favicon-32.png rel=icon sizes=32x32 type=image/png><link href=/favicon-180.png rel=icon sizes=180x180 type=image/png><link href=/favicon-524.png rel=icon sizes=524x524 type=image/png><style>body{--primary-color:#5871a2;--primary-pale-color:#5871a233;--primary-decoration-color:#5871a210;--bg-color:#fff;--text-color:#2f3030;--text-pale-color:#767676;--text-decoration-color:#a9a9a9;--highlight-mark-color:#5f75b020;--callout-note-color:#5871a2;--callout-tip-color:#268556;--callout-important-color:#885fc9;--callout-warning-color:#ab6632;--callout-caution-color:#c64e4e}body.dark{--primary-color:#6f8fd1;--primary-pale-color:#6f8fd166;--primary-decoration-color:#6f8fd112;--bg-color:#1c1c1c;--text-color:#c1c1c1;--text-pale-color:#848484;--text-decoration-color:#5f5f5f;--highlight-mark-color:#8296cb3b;--callout-note-color:#6f8fd1;--callout-tip-color:#47976f;--callout-important-color:#9776cd;--callout-warning-color:#ad7a52;--callout-caution-color:#d06161}body{--main-font:ui-sans-serif,system-ui,sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";--code-font:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;--homepage-max-width:768px;--main-max-width:768px;--avatar-size:56px;--font-size:16px;--line-height:1.75;--img-border-radius:0px;--detail-border-radius:0px;--dark-mode-img-brightness:.75;--dark-mode-chart-brightness:.75;--inline-code-border-radius:2px;--inline-code-bg-color:var(--primary-decoration-color);--block-code-border-radius:0px;--block-code-border-color:var(--primary-color);--detail-border-color:var(--primary-color)}</style><link href=https://blackpath.blog/main.css rel=stylesheet><link href=/hl-dark.css id=hl rel=stylesheet><body class="post dark"><div id=wrapper><div id=blank></div><aside><button aria-label="back to top" id=back-to-top><svg class="feather feather-arrow-up" viewbox="0 0 24 24" fill=none height=18 stroke=currentColor stroke-linecap=round stroke-linejoin=round stroke-width=2 width=18 xmlns=http://www.w3.org/2000/svg><line x1=12 x2=12 y1=19 y2=5></line><polyline points="5 12 12 5 19 12"></polyline></svg></button></aside><main><header><nav><a href=https://blackpath.blog/posts id=backlink>← Back</a></nav></header><div><div data-check-icon='<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="18" height="18"><path d="M10.0007 15.1709L19.1931 5.97852L20.6073 7.39273L10.0007 17.9993L3.63672 11.6354L5.05093 10.2212L10.0007 15.1709Z" fill="currentColor"></path></svg>
' data-copy-icon='<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="18" height="18"><path d="M6.9998 6V3C6.9998 2.44772 7.44752 2 7.9998 2H19.9998C20.5521 2 20.9998 2.44772 20.9998 3V17C20.9998 17.5523 20.5521 18 19.9998 18H16.9998V20.9991C16.9998 21.5519 16.5499 22 15.993 22H4.00666C3.45059 22 3 21.5554 3 20.9991L3.0026 7.00087C3.0027 6.44811 3.45264 6 4.00942 6H6.9998ZM5.00242 8L5.00019 20H14.9998V8H5.00242ZM8.9998 6H16.9998V16H18.9998V4H8.9998V6Z" fill="currentColor"></path></svg>
' id=copy-cfg style=display:none></div><article class=prose><h1 class=post-title><span>Media Manipulation With AI</span> </h1><div id=post-info><div id=date><span id=publish>Apr 12, 2025</span></div><div id=tags><a class=instant href=https://blackpath.blog//tags/ai><span>#</span>AI</a><a class=instant href=https://blackpath.blog//tags/politics><span>#</span>Politics</a><a class=instant href=https://blackpath.blog//tags/media><span>#</span>Media</a></div></div><figure><img alt="Abbi and Ilana freak out over Hillary Clinton" src=/images/broad_city_cringe.png><figcaption><small>Believe it or not, no one is about to be arrested for public indecency in this scene.</small></figcaption></figure><p>Last year, I attended the recording of a podcast called Austinprenure in Texas (episode is <a href="https://podcasts.apple.com/us/podcast/combating-disinformation-with-knowledge-graphs-and-llms/id1446779826?i=1000670542827" rel="noopener nofollow noreferrer" target=_blank>here</a>, my questions start at around the 35:00 mark). The guest described their work to trace the flow of radicalization through central europe. His description was very general (likely because much of it is classified), but from what I understand, it involved ingesting huge amounts of media content created in central europe and analyzing it for particular messages, then watching how those messages were propagated on social and traditional media to identify sources that were responsible for radicalization.<p>My question was whether this could be done in reverse. It seems like it could. I've heard image generation from plain text described as just the opposite of description generation for images. While it may not be <em>exactly</em> the reverse in a you-can-just-run-this-model-backwards sort of way, it seems obvious that if the technology exists to generate descriptions for images, then the technology <em>also</em> exists to generate an image from plain text descriptions. In the same way, if you have a model that can ingest media and then describe the radicalization that might result from it, then the technology <em>also</em> exists to describe radicalization and then generate media that pushes people toward it.<p>A system like this might even be able to influence political and cultural views without ever producing content that would be considered political (or even relevant). In <a rel="noopener nofollow noreferrer" href=https://slatestarcodex.com/2014/09/30/i-can-tolerate-anything-except-the-outgroup/ target=_blank>an old blog post</a> by Scott Alexander, he writes-<blockquote><p>The Blue Tribe is most classically typified by liberal political beliefs, vague agnosticism, supporting gay rights, thinking guns are barbaric, eating arugula, drinking fancy bottled water, driving Priuses, reading lots of books, being highly educated, mocking American football...</blockquote><p>It seems possible that making someone less interested in football might actually make them more liberal politically, in a tail-wags-dog sort of way. If someone who was a fan of the sport becomes less interested, they'll stop hanging out with friends who are still following the game. They may have fewer parties with those friends. They may be more willing to view and read content from <em>other</em> people (likely liberal) who dislike the game. Their friend group may slowly shift to the left, politically. Although it's difficult to find any research on this (if you have any, feel free to email me), just at first glance, this seems like something that could happen. The real question is- how do you reduce interest in football?<p>Driving this change in interest is hard, but not impossible. If you have control of their social media feeds (which are almost always algorithmically driven to one degree or another), you might naively assume that you could just insert some anti-football content. This is unlikely to work, because people often become more entrenched in their views when those views are challanged<sup class=footnote-reference><a href=#1>1</a></sup>. What likely <em>would</em> work is providing ostensibly pro-football content that's just... <em>cringe</em>.<p>For an example of cringe, <a href="https://www.youtube.com/watch?v=lJgM4_C3gvE" rel="noopener nofollow noreferrer" target=_blank>here</a> is the scene in <a rel="noopener nofollow noreferrer" href=https://en.wikipedia.org/wiki/Broad_City target=_blank>Broad City</a> where I totally lost interest in the show. Not because I especially dislike Hillary Clinton, but because this level of adoration toward <em>any</em> politician is unsettling and cringey to me. I understand they were playing it for laughs, but I didn't laugh. I winced.<figure><img alt="Comments on the Broad City Hillary Clinton cameo" src=/images/broad_city_comments.png><figcaption><small>So did everyone else.</small></figcaption></figure><p>I don't want to pick on Broad City, specifically, but it was the first example that came to mind. I stopped watching the show after this scene. Did it make me more conservative? Not in any noticeable way. But what if I regularly viewed content that highlighted the most cringe-inducing, silly, or ridiculous people that share my own ideology, even while supposedly supporting them? I would like to believe that I'm immune to this sort of soft-propaganda, but I've met too many people who thought the same and were wrong. Given enough time, I think it might push me away from what I currently believe.<p>And just to be clear, this is only <em>one</em> example of <em>one</em> way in which someone could be influenced. Maybe our model doesn't generate cringe- maybe it introduces them to local organizations that are A) related to something they're interested in, and B) already stacked with people slightly to one side of their current political alignment. Maybe it promotes content from friends they haven't seen in a while who share <em>most</em> of their views, but have crucial differences. Maybe they tend to match with people on Tinder that don't like football. There is a huge space of possible ways to influence someone when you're ingesting terabytes of data and mining it for fuzzy and exploitable relationships in order to do it.<p>Any organized attempt to do this at scale would be a massive undertaking, likely requiring access to huge amounts of user data, intimate control over the content that those users are consuming, and some serious improvements in AI technology. Unfortunately, all of those things are becoming easier with time. People are using social media more than ever before, and these platforms collect vast amounts of information on them<sup class=footnote-reference><a href=#2>2</a></sup>, while AI is only becoming more capable<sup class=footnote-reference><a href=#3>3</a></sup>. The feeds that people use to discover new content are almost entirely algorithmic now, with only a few platforms stubbornly clinging to chronological or category-based recommendations, and the "algorithms" are more likely to be AI. At the same time, people are more likely to self-sort into <a rel="noopener nofollow noreferrer" href=https://en.wikipedia.org/wiki/Filter_bubble target=_blank>isolated</a> (read: vulnerable) communities that share common beliefs.<p>It would be difficult, but not impossible, even with current technology. And it's only going to become <em>more</em> possible.<p>Given enough data, enough control over what people see, and strong enough AI, you could build a system that generates content designed to sway an entire population into believing particular things. If such a system were controlled by the Metas and Tiktoks of the world, then it would probably be used to deliberately excise radical or undesireable elements from their platform, increase user engagement, and generate profit in various ways, all without ever doing anything that most users would recognize as manipulative. But once the tools are in place, how long would it take them to be used on behalf of the state?<p>Social media companies have already been accused of censoring or de-emphasizing political views on the right and the left. Whether any particular accusation has merit or not, it's definitely something that <em>could</em> happen. If Twitter had a tool in place that could incrementally and almost unnoticeably shift the discourse in one direction or another, I have difficulty imagining that tool not eventually being used to placate the US government.<p>And if the content is funny and interesting, people will watch it. If, sometimes, a few people see an uptick in content that makes them roll their eyes at their own party, tribe, or demographic, who cares? It's not like they're going to go out and start campaigning for [insert other political party here].<p>Well, not the <em>first</em> time they see it. Or the second. But eventually? Maybe.<p>Do I think that anyone in the current administration would try to build something like this? No. This isn't because I have faith in their essential goodness, but because I don't think any of them understand that it's even possible. But some people working for the military or intelligence community likely have some idea that it is, and are competant enough to build it. As the barriers continue to lower, something like this will gradually become more and more likely.<figure><img alt="Tech company builds the Torment Nexus" src=/images/torment_nexus.jpeg><figcaption><small>Twitter would build the Torment Nexus for a 5% bump in user retention.</small></figcaption></figure><p>Beyond companies influencing public opinion for engagement and money, beyond governments using the same tools to manipulate and control their citizens (I'm looking at you, China), there's the threat of rogue AI doing the same.<p>While I'm not a fervent believer in the rise of superintelligent artificial intelligence, I don't entirely discount it. I've already discussed the <a rel="noopener nofollow noreferrer" href=https://ai-2027.com/ target=_blank>AI 2027</a> scenario in another post, and if something even vaguely similar to that scenario were to occur, this is another way that an agentic AI could manipulate public opinion. Are people pissed over losing their jobs? Are they scared of a fully autonomous economy? If tools like this exist, then any agent worth it's compute would be able to paint dissidents as luddites and gather support without ever doing anything that a human being could point to as manipulative.<p>So anyway. That's it. Enjoy the existential dread.<div class=footnote-definition id=1><sup class=footnote-definition-label>1</sup><p>"...when exposed to arguments supporting positions different from their prior views, people often (though perhaps not always) become even more convinced of their prior views rather than being swayed by arguments" - <a rel="noopener nofollow noreferrer" href=https://academic.oup.com/aristotelian/article/123/2/173/7207975 target=_blank>Can Arguments Change Minds?</a></div><div class=footnote-definition id=2><sup class=footnote-definition-label>2</sup><p>"We collect information about how you use our Products, such as the types of content you view or engage with; the features you use; the actions you take; the people or accounts you interact with; and the time, frequency and duration of your activities." - <a rel="noopener nofollow noreferrer" href=https://www.facebook.com/about/privacy/update/printable target=_blank>Facebook Data Policy</a></div><div class=footnote-definition id=3><sup class=footnote-definition-label>3</sup><p>"The overall performance of LMs gets reliably better as investment increases. Rapid progress in LMs has primarily come from simply training larger models on more data" - <a rel="noopener nofollow noreferrer" href=https://theaidigest.org/progress-and-dangers target=_blank>AI Digest</a></div></article></div><footer><div class=left><div class=copyright>© 2025 Michael House</div></div><div class=right><a href=https://blackpath.blog/posts/feed.xml id=rss-btn>RSS</a></div></footer><dialog id=rss-mask><div><a href=https://blackpath.blog/posts/feed.xml>https://blackpath.blog/posts/feed.xml</a><button data-check-icon='<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="18" height="18"><path d="M10.0007 15.1709L19.1931 5.97852L20.6073 7.39273L10.0007 17.9993L3.63672 11.6354L5.05093 10.2212L10.0007 15.1709Z" fill="currentColor"></path></svg>
' data-copy-icon='<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="18" height="18"><path d="M6.9998 6V3C6.9998 2.44772 7.44752 2 7.9998 2H19.9998C20.5521 2 20.9998 2.44772 20.9998 3V17C20.9998 17.5523 20.5521 18 19.9998 18H16.9998V20.9991C16.9998 21.5519 16.5499 22 15.993 22H4.00666C3.45059 22 3 21.5554 3 20.9991L3.0026 7.00087C3.0027 6.44811 3.45264 6 4.00942 6H6.9998ZM5.00242 8L5.00019 20H14.9998V8H5.00242ZM8.9998 6H16.9998V16H18.9998V4H8.9998V6Z" fill="currentColor"></path></svg>
' aria-label=copy autofocus data-link=https://blackpath.blog/posts/feed.xml><svg viewbox="0 0 24 24" height=18 width=18 xmlns=http://www.w3.org/2000/svg><path d="M6.9998 6V3C6.9998 2.44772 7.44752 2 7.9998 2H19.9998C20.5521 2 20.9998 2.44772 20.9998 3V17C20.9998 17.5523 20.5521 18 19.9998 18H16.9998V20.9991C16.9998 21.5519 16.5499 22 15.993 22H4.00666C3.45059 22 3 21.5554 3 20.9991L3.0026 7.00087C3.0027 6.44811 3.45264 6 4.00942 6H6.9998ZM5.00242 8L5.00019 20H14.9998V8H5.00242ZM8.9998 6H16.9998V16H18.9998V4H8.9998V6Z" fill=currentColor></path></svg></button></div></dialog></main></div><script src=/js/lightense.min.js></script><script src=/js/popper.min.js></script><script src=/js/tippy.min.js></script><script>const referrer = document.referrer;
  const domain = window.location.origin;

  console.log(referrer);
  
  // if the visitor is coming from offsite, then remove
  // the lastUrl from local storage
  if(!!referrer && !referrer.includes(domain)){
    localStorage.removeItem('lastUrl');
  }

  const backButton = document.getElementById('backlink');
  const lastUrl = localStorage.getItem('lastUrl');

  // if a backlink has been set in local storage, then update
  // the actual button on the page to go there
  if(lastUrl != null) {
    backButton.href = lastUrl;
  }

  const links = document.getElementsByClassName('footnote-reference');
  const notes = document.getElementsByClassName('footnote-definition');

  for(let i = 0; i < links.length; ++i){
    let id = links[i].getElementsByTagName('a')[0].getAttribute('href').replace('#','');
    for(let j = 0; j < notes.length; ++j){
      if(id == notes[j].id){
        let content = notes[j].getElementsByTagName('p')[0];
        tippy(links[i], {
          content: content.cloneNode(true),
          interactive: true,
          allowHTML: true,
        });
      }
    }
  }</script><script src=https://blackpath.blog/js/main.js></script>